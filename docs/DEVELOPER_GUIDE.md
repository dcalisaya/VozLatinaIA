# Developer Guide üõ†Ô∏è

Welcome to the **VozLatina AI** developer documentation. This guide is intended for contributors, hackers, and engineers who want to understand or modify the core logic of the project.

## üèó Architecture Overview

VozLatina AI is built on top of **ComfyUI**, utilizing a custom node architecture to encapsulate complex AI workflows into simple, reusable components.

### Core Components

1.  **`custom_nodes/VozLatina/nodes.py`**: The heart of the backend. It defines the custom nodes and their logic.
2.  **`custom_nodes/VozLatina/__init__.py`**: Exposes the nodes to ComfyUI, making the folder a valid custom node pack.
3.  **`LazyLoadModel`**: A helper class designed to manage VRAM usage aggressively.
4.  **FP8 Optimization**: We utilize `torch.float8_e4m3fn` on supported hardware.

---

## üîå Custom Nodes API

The project currently exposes 4 main nodes. Below is the technical specification for each.

### 1. VozLatina RVC Inference
*Performs Voice Conversion using Retrieval-based Voice Conversion (RVC).*

*   **Class**: `VozLatinaRVC`
*   **Inputs**:
    *   `audio` (AUDIO): The source audio to convert.
    *   `model_name` (STRING): Filename of the `.pth` model (e.g., `bad_bunny.pth`).
    *   `f0_method` (STRING): Pitch extraction method (`rmvpe` recommended for quality, `crepe` for accuracy).
    *   `fp8_enabled` (BOOLEAN): If `True`, attempts to cast weights to FP8.
*   **Outputs**:
    *   `AUDIO`: The converted voice audio.

### 2. VozLatina Audio Restore
*Cleans up audio artifacts generated by TTS or RVC using DeepFilterNet.*

*   **Class**: `VozLatinaAudioRestore`
*   **Inputs**:
    *   `audio` (AUDIO): Noisy input audio.
    *   `intensity` (FLOAT): 0.0 to 1.0. (Currently a placeholder for mixing ratio).
*   **Outputs**:
    *   `AUDIO`: Cleaned audio.
*   **Dependencies**: Requires `deepfilternet` python package.

### 3. VozLatina LivePortrait
*Animate a static face image using driving audio.*

*   **Class**: `VozLatinaLivePortrait`
*   **Inputs**:
    *   `source_image` (IMAGE): The reference face.
    *   `driving_audio` (AUDIO): Speech audio.
    *   `lip_sync_ratio` (FLOAT): Strength of the lip movement.
    *   `fp8_enabled` (BOOLEAN): FP8 optimization toggle.
*   **Outputs**:
    *   `IMAGE`: A sequence of frames (video).

### 4. VozLatina Watermark
*Injects invisible metadata into the generated video frames for ethical compliance.*

*   **Class**: `VozLatinaWatermark`
*   **Technique**: **LSB (Least Significant Bit) Steganography**.
    *   We encode the `watermark_text` into the **Blue channel** of the first pixels of the first frame.
    *   This is invisible to the naked eye but retrievable programmatically.
*   **Inputs**:
    *   `video_frames` (IMAGE): The generated video frames.
    *   `watermark_text` (STRING): The text to hide (default: "Generated by VozLatina AI").
*   **Outputs**:
    *   `IMAGE`: The watermarked frames.

---

## ü§ù Contribution Guidelines

We welcome Pull Requests! Please follow these rules:

1.  **Code Style**: We use `black` for Python formatting.
    ```bash
    pip install black
    black custom_nodes/VozLatina/nodes.py
    ```
2.  **Type Hinting**: All new nodes must have `INPUT_TYPES` and `RETURN_TYPES` strictly defined to ensure compatibility with the ComfyUI frontend.
3.  **Testing**:
    *   Since we don't have a full CI/CD for GPU inference yet, please run a **Syntax Check** before pushing:
        ```bash
        python3 -m py_compile custom_nodes/VozLatina/nodes.py
        ```
    *   If you add a new dependency, update `custom_nodes/VozLatina/requirements.txt`.

### Roadmap for Contributors
Check `docs/ROADMAP.md` for the latest tasks. We currently need help with:
*   Implementing the actual `torch.load` logic for RVC.
*   Connecting the `desktop_app` via WebSockets.
